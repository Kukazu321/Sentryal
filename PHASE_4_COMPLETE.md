# âœ… PHASE 4 COMPLÃˆTE : IntÃ©gration HyP3 + Worker + Parser GeoTIFF

## ğŸ¯ Objectif

Automatiser complÃ¨tement le traitement InSAR :
1. CrÃ©er un job HyP3
2. Polling automatique du statut
3. TÃ©lÃ©chargement des GeoTIFF
4. Parsing des dÃ©formations
5. Stockage en base de donnÃ©es

---

## ğŸ“ Fichiers crÃ©Ã©s

### 1. `backend/src/workers/insarWorker.ts`
**Worker BullMQ pour polling et traitement des jobs InSAR**

#### Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Route      â”‚ POST /api/jobs/process-insar
â”‚  (jobs.ts)      â”‚ â†’ CrÃ©e job HyP3
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â†’ Ajoute Ã  la queue
         â”‚
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BullMQ Queue   â”‚ Redis-backed
â”‚  (insarQueue)   â”‚ â†’ Stocke job IDs
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ (polling toutes les 30s)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker         â”‚ 5 workers en parallÃ¨le
â”‚  (insarWorker)  â”‚ â†’ Poll HyP3 API
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â†’ TÃ©lÃ©charge GeoTIFF
         â”‚         â†’ Parse dÃ©formations
         â†“         â†’ Stocke en DB
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL     â”‚
â”‚  (deformations) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### FonctionnalitÃ©s
- âœ… **Polling automatique** : VÃ©rifie le statut toutes les 30s
- âœ… **Retry avec backoff** : 50 tentatives max (25 minutes)
- âœ… **TÃ©lÃ©chargement automatique** : GeoTIFF files quand SUCCEEDED
- âœ… **Parsing automatique** : Extraction des dÃ©formations
- âœ… **Stockage atomique** : Transaction pour garantir la cohÃ©rence
- âœ… **Cleanup** : Suppression des fichiers temporaires (production)
- âœ… **Scalable** : 5 workers en parallÃ¨le, rate limiting
- âœ… **Monitoring** : Logs structurÃ©s avec Pino

#### Configuration
```typescript
// Queue options
defaultJobOptions: {
  attempts: 50,           // 50 retries max
  backoff: {
    type: 'fixed',
    delay: 30000,         // 30 seconds between polls
  },
}

// Worker options
concurrency: 5,           // 5 jobs in parallel
limiter: {
  max: 10,                // Max 10 jobs per minute
  duration: 60000,        // Respect HyP3 API rate limits
}
```

#### Utilisation
```typescript
import { insarQueue } from './workers/insarWorker';

// Ajouter un job Ã  la queue
await insarQueue.add('process-insar', {
  jobId: 'db-job-uuid',
  hyp3JobId: 'hyp3-job-id',
  infrastructureId: 'infra-uuid',
  createdAt: Date.now(),
});
```

---

### 2. `backend/src/services/geotiffParser.ts`
**Service de parsing des fichiers GeoTIFF InSAR**

#### FonctionnalitÃ©s
- âœ… **Parse GeoTIFF** : Lit les fichiers 32-bit floating-point
- âœ… **Conversion lat/lon â†’ pixel** : Transformation affine
- âœ… **Extraction multi-fichiers** : Vertical, LOS, Coherence
- âœ… **Filtrage qualitÃ©** : Coherence minimale (default: 0.3)
- âœ… **Conversion unitÃ©s** : MÃ¨tres â†’ MillimÃ¨tres (prÃ©cision 0.01mm)
- âœ… **Gestion NoData** : DÃ©tection et skip des valeurs invalides
- âœ… **Statistiques** : Min/max/mean/stdDev pour validation
- âœ… **Extraction date** : Parse filename HyP3 (S1AA_YYYYMMDD_YYYYMMDD)

#### Format GeoTIFF HyP3
```
Fichiers gÃ©nÃ©rÃ©s par HyP3 :
â”œâ”€ *_vert_disp.tif    â†’ DÃ©placement vertical (up/down)
â”œâ”€ *_los_disp.tif     â†’ DÃ©placement ligne de visÃ©e (towards/away)
â”œâ”€ *_corr.tif         â†’ CohÃ©rence (qualitÃ©, 0.0-1.0)
â””â”€ *_unw_phase.tif    â†’ Phase dÃ©roulÃ©e (avancÃ©)

Format :
- 32-bit floating-point
- Valeurs en MÃˆTRES
- NoData : -9999 ou NaN
- GÃ©orÃ©fÃ©rencÃ© (EPSG:4326 ou projection locale)
```

#### Algorithme de conversion lat/lon â†’ pixel
```typescript
// Affine transformation
x = (lon - bbox[0]) / (bbox[2] - bbox[0]) * width
y = (bbox[3] - lat) / (bbox[3] - bbox[1]) * height

// Note: Y est inversÃ© (origine top-left)
```

#### Utilisation
```typescript
import { geotiffParser } from './services/geotiffParser';

// Parse vertical displacement
const deformations = await geotiffParser.parseVerticalDisplacement(
  '/path/to/vert_disp.tif',
  points, // Array<{ id, latitude, longitude }>
  {
    losDisplacementPath: '/path/to/los_disp.tif', // Optional
    coherencePath: '/path/to/corr.tif',           // Optional
    minCoherence: 0.3,                            // Filter low quality
  }
);

// RÃ©sultat :
// [
//   {
//     pointId: 'uuid',
//     date: Date,
//     verticalDisplacementMm: 12.45,  // mm (2 dÃ©cimales)
//     losDisplacementMm: 8.32,        // mm (optionnel)
//     coherence: 0.87,                // 0.0-1.0 (optionnel)
//   },
//   ...
// ]
```

#### Statistiques (debugging)
```typescript
const stats = await geotiffParser.getStatistics('/path/to/vert_disp.tif');
// {
//   min: -15.23,        // mm
//   max: 42.18,         // mm
//   mean: 2.45,         // mm
//   stdDev: 8.12,       // mm
//   noDataCount: 1234,
//   validCount: 98765,
// }
```

---

## ğŸ”„ Flow complet

### 1. CrÃ©ation du job (API)
```typescript
// POST /api/jobs/process-insar
{
  "infrastructureId": "uuid"
}

// Backend :
1. VÃ©rifie que l'infrastructure existe
2. RÃ©cupÃ¨re les points
3. Calcule le bbox agrÃ©gÃ©
4. CrÃ©e le job HyP3 (hyP3Service.createJob)
5. Stocke en DB (status: PENDING)
6. Ajoute Ã  la queue BullMQ
7. Retourne job_id
```

### 2. Polling (Worker)
```typescript
// Worker BullMQ (toutes les 30s)
1. Poll HyP3 API : GET /jobs?job_id=xxx
2. Update DB : status = PENDING/RUNNING/SUCCEEDED/FAILED
3. Si PENDING/RUNNING : throw error â†’ retry dans 30s
4. Si FAILED : mark as FAILED, stop
5. Si SUCCEEDED : continue au tÃ©lÃ©chargement
```

### 3. TÃ©lÃ©chargement (Worker)
```typescript
// Quand status = SUCCEEDED
1. RÃ©cupÃ¨re les URLs des fichiers (files[])
2. Trouve *_vert_disp.tif (obligatoire)
3. Trouve *_los_disp.tif (optionnel)
4. Trouve *_corr.tif (optionnel)
5. TÃ©lÃ©charge dans /tmp/geotiff/{jobId}/
6. Stocke les fichiers sur disque
```

### 4. Parsing (Worker)
```typescript
// Parse GeoTIFF
1. RÃ©cupÃ¨re tous les points de l'infrastructure
2. Ouvre les GeoTIFF (geotiff.js)
3. Lit les rasters (Float32Array)
4. Pour chaque point :
   a. Convertit lat/lon â†’ pixel x/y
   b. Lit la valeur du pixel
   c. VÃ©rifie NoData
   d. VÃ©rifie coherence > 0.3
   e. Convertit mÃ¨tres â†’ millimÃ¨tres
5. Retourne array de deformations
```

### 5. Stockage (Worker)
```typescript
// Insert en DB (transaction)
1. BEGIN TRANSACTION
2. Pour chaque deformation :
   INSERT INTO deformations (
     point_id, job_id, date,
     vertical_displacement_mm,
     los_displacement_mm,
     coherence
   ) VALUES (...)
   ON CONFLICT (point_id, date) DO UPDATE
3. COMMIT
4. Update jobs.status = COMPLETED
5. Cleanup fichiers temporaires (production)
```

---

## ğŸ—„ï¸ SchÃ©ma de base de donnÃ©es

### Table `deformations`
```sql
CREATE TABLE deformations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  point_id UUID NOT NULL REFERENCES points(id) ON DELETE CASCADE,
  job_id UUID NOT NULL REFERENCES jobs(id) ON DELETE CASCADE,
  date DATE NOT NULL,
  vertical_displacement_mm DECIMAL(10, 3),  -- PrÃ©cision 0.001mm
  los_displacement_mm DECIMAL(10, 3),       -- Optionnel
  coherence DECIMAL(3, 2),                  -- 0.00-1.00
  created_at TIMESTAMP DEFAULT NOW(),
  updated_at TIMESTAMP DEFAULT NOW(),
  
  -- Contrainte unique : 1 seule dÃ©formation par point/date
  UNIQUE (point_id, date)
);

-- Index pour requÃªtes rapides
CREATE INDEX idx_deformations_point_id ON deformations(point_id);
CREATE INDEX idx_deformations_job_id ON deformations(job_id);
CREATE INDEX idx_deformations_date ON deformations(date);
CREATE INDEX idx_deformations_point_date ON deformations(point_id, date);
```

### Table `jobs` (mise Ã  jour)
```sql
CREATE TYPE job_status AS ENUM ('PENDING', 'RUNNING', 'SUCCEEDED', 'FAILED', 'COMPLETED');

ALTER TABLE jobs ADD COLUMN result_files JSONB;
ALTER TABLE jobs ADD COLUMN completed_at TIMESTAMP;

-- result_files format :
-- [
--   {
--     "url": "https://...",
--     "filename": "S1AA_..._vert_disp.tif",
--     "size": 15234567
--   },
--   ...
-- ]
```

---

## ğŸš€ DÃ©marrage

### 1. Installer Redis (requis pour BullMQ)
```powershell
# Via Docker
docker run -d --name redis -p 6379:6379 redis:7-alpine

# Ou via WSL/Linux
sudo apt install redis-server
redis-server
```

### 2. Variables d'environnement
```env
# .env
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# HyP3 API
HYP3_API_URL=https://hyp3-api.asf.alaska.edu
EARTHDATA_BEARER_TOKEN=your-token-here

# Mode dev (mock si pas de token)
NODE_ENV=development
```

### 3. DÃ©marrer le worker
```typescript
// backend/src/index.ts
import './workers/insarWorker'; // Import pour dÃ©marrer le worker

// Le worker dÃ©marre automatiquement et Ã©coute la queue
```

### 4. Tester le flow complet
```powershell
# 1. CrÃ©er un job InSAR
curl -X POST http://localhost:5000/api/jobs/process-insar \
  -H "Authorization: Bearer YOUR_SUPABASE_JWT" \
  -H "Content-Type: application/json" \
  -d '{"infrastructureId": "uuid"}'

# 2. Le worker poll automatiquement toutes les 30s

# 3. VÃ©rifier les logs
# Logs du worker :
# - "Processing InSAR job"
# - "HyP3 job status retrieved"
# - "Job succeeded, processing results"
# - "Downloaded vertical displacement file"
# - "Parsed deformations from GeoTIFF"
# - "Stored deformations in database"
# - "InSAR job processing completed successfully"

# 4. VÃ©rifier en DB
SELECT * FROM jobs WHERE id = 'job-uuid';
SELECT * FROM deformations WHERE job_id = 'job-uuid';
```

---

## ğŸ“Š Monitoring

### Logs structurÃ©s (Pino)
```json
{
  "level": "info",
  "time": "2024-01-18T10:30:00.000Z",
  "jobId": "uuid",
  "hyp3JobId": "hyp3-id",
  "status": "SUCCEEDED",
  "msg": "HyP3 job status retrieved"
}
```

### MÃ©triques importantes
- **Temps de traitement** : De PENDING Ã  COMPLETED
- **Taux de succÃ¨s** : SUCCEEDED vs FAILED
- **Points valides** : % de points avec donnÃ©es valides
- **Coherence moyenne** : QualitÃ© des donnÃ©es InSAR

### BullMQ Dashboard (optionnel)
```bash
npm install -g bull-board
bull-board --redis redis://localhost:6379
# Ouvre http://localhost:3000
```

---

## ğŸ› Debugging

### ProblÃ¨me : Worker ne dÃ©marre pas
```bash
# VÃ©rifier Redis
redis-cli ping
# Doit retourner : PONG

# VÃ©rifier les logs
tail -f backend/logs/app.log
```

### ProblÃ¨me : Job reste en PENDING
```bash
# VÃ©rifier le statut HyP3
curl https://hyp3-api.asf.alaska.edu/jobs?job_id=xxx \
  -H "Authorization: Bearer YOUR_TOKEN"

# VÃ©rifier la queue BullMQ
redis-cli
> KEYS bull:insar-processing:*
> HGETALL bull:insar-processing:job-id
```

### ProblÃ¨me : Parsing Ã©choue
```typescript
// Tester le parser directement
import { geotiffParser } from './services/geotiffParser';

const stats = await geotiffParser.getStatistics('/path/to/file.tif');
console.log(stats);
// VÃ©rifie min/max/mean pour dÃ©tecter les anomalies
```

---

## âš¡ Performance

### Optimisations implÃ©mentÃ©es
- âœ… **Batch insert** : Transaction pour toutes les dÃ©formations
- âœ… **Parallel workers** : 5 workers simultanÃ©s
- âœ… **Rate limiting** : Max 10 jobs/minute (respect HyP3 API)
- âœ… **Cleanup automatique** : Suppression fichiers temporaires
- âœ… **Index DB** : Index sur point_id, date pour requÃªtes rapides

### Benchmarks (estimÃ©s)
- **Polling overhead** : ~100ms par poll
- **Download GeoTIFF** : ~5-10s pour 3 fichiers (15MB chacun)
- **Parsing** : ~2-5s pour 5000 points
- **DB insert** : ~1-3s pour 5000 dÃ©formations
- **Total** : ~10-20s aprÃ¨s que HyP3 ait terminÃ©

---

## ğŸ” SÃ©curitÃ©

### Gestion des tokens
- âœ… Bearer token stockÃ© en env (pas en DB)
- âœ… Pas de token dans les logs
- âœ… Validation des URLs de tÃ©lÃ©chargement

### Isolation
- âœ… Fichiers temporaires dans /tmp/{jobId}/ (isolÃ©s)
- âœ… Cleanup automatique aprÃ¨s traitement
- âœ… Validation des donnÃ©es avant insertion

---

## ğŸ“ TODO (AmÃ©liorations futures)

### Phase 4.1 : Webhooks HyP3
- [ ] Route `/api/webhooks/hyp3-callback`
- [ ] Validation signature HyP3
- [ ] Traitement immÃ©diat (pas de polling)

### Phase 4.2 : Notifications
- [ ] WebSocket pour notifier le frontend
- [ ] Email quand job terminÃ©
- [ ] Push notifications (mobile)

### Phase 4.3 : Cache
- [ ] Cache Redis pour les statistiques
- [ ] Cache des GeoTIFF parsÃ©s
- [ ] Invalidation automatique

### Phase 4.4 : Monitoring avancÃ©
- [ ] Prometheus metrics
- [ ] Grafana dashboards
- [ ] Alertes Sentry

---

## âœ… Checklist Phase 4

- [x] Worker BullMQ crÃ©Ã©
- [x] Parser GeoTIFF crÃ©Ã©
- [x] Polling automatique implÃ©mentÃ©
- [x] TÃ©lÃ©chargement automatique implÃ©mentÃ©
- [x] Parsing automatique implÃ©mentÃ©
- [x] Stockage en DB implÃ©mentÃ©
- [x] Gestion des erreurs
- [x] Logs structurÃ©s
- [x] Documentation complÃ¨te
- [ ] Tests unitaires (Phase 8)
- [ ] Tests d'intÃ©gration (Phase 8)

---

## ğŸ¯ Prochaine Ã©tape : PHASE 5 (Dashboard)

Maintenant que les donnÃ©es sont en DB, on peut crÃ©er le dashboard pour les visualiser !

**Fichiers Ã  crÃ©er :**
- `backend/src/routes/dashboard.ts` - API pour rÃ©cupÃ©rer les dÃ©formations
- `frontend/src/components/InfrastructureMap.tsx` - Carte interactive
- `frontend/src/components/Heatmap.tsx` - Heatmap des dÃ©formations
- `frontend/src/pages/dashboard/[id].tsx` - Page dashboard

**Voir `PHASE_5_DASHBOARD.md` pour les dÃ©tails.**
